{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "NyPlEamI5igM",
   "metadata": {
    "id": "NyPlEamI5igM"
   },
   "source": [
    "# Author\n",
    "\n",
    "Luiz Gustavo Mugnaini Anselmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wJwZQmDweqdm",
   "metadata": {
    "id": "wJwZQmDweqdm"
   },
   "source": [
    "# Using `pytorch` to solve the MNIST dataset classification problem\n",
    "\n",
    "In this notebook I implement two method for classiying the classic [MNIST](https://en.wikipedia.org/wiki/MNIST_database), one with a fully connected neural network and another with a convolutional neural network. In both cases we analyze the effect of different optimizers and loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuP_PSW1qdQn",
   "metadata": {
    "id": "nuP_PSW1qdQn"
   },
   "source": [
    "# MNIST setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TWDrVdP05bD9",
   "metadata": {
    "id": "TWDrVdP05bD9"
   },
   "source": [
    "## Imports\n",
    "\n",
    "Here we list all imports that will be used throughout this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005ad930-8b04-40ab-bff6-75510ec9cc3c",
   "metadata": {
    "id": "005ad930-8b04-40ab-bff6-75510ec9cc3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BxDBgtQJqT_n",
   "metadata": {
    "id": "BxDBgtQJqT_n"
   },
   "source": [
    "Setting configurations for working with `pytorch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gayF_RzSIhcu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gayF_RzSIhcu",
    "outputId": "08620610-fc00-4b8f-ad0f-bccbd775b8f9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(293819)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "py5aP3qU53IK",
   "metadata": {
    "id": "py5aP3qU53IK"
   },
   "source": [
    "## Data fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1W2c5RfFqrw4",
   "metadata": {
    "id": "1W2c5RfFqrw4"
   },
   "source": [
    "For the data fetching, we first set a constant determining the batch size used by the data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CBowOZcp2mE5",
   "metadata": {
    "id": "CBowOZcp2mE5"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HylZNwVG2qKP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HylZNwVG2qKP",
    "outputId": "788f1140-a11a-4cb4-dce4-bd98262295df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 42211072.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 26664251.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 31242591.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 14836860.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415a466-9524-473e-8f08-3d15154ad2f9",
   "metadata": {
    "id": "b415a466-9524-473e-8f08-3d15154ad2f9"
   },
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KISZ4hGP2-B1",
   "metadata": {
    "id": "KISZ4hGP2-B1"
   },
   "source": [
    "## Getting to know the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4oFGEAbb3CU4",
   "metadata": {
    "id": "4oFGEAbb3CU4"
   },
   "source": [
    "Lets first get the image resolution of the MNIST samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P9HNX1jAGjsU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9HNX1jAGjsU",
    "outputId": "8718775e-d06f-4dd1-b0b4-6605057c3c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image height: 28\n",
      "Image width: 28\n"
     ]
    }
   ],
   "source": [
    "sample0_np = train_data[0][0].numpy().squeeze()\n",
    "IMG_HEIGHT, IMG_WIDTH = sample0_np.shape\n",
    "print(f\"Image height: {IMG_HEIGHT}\\nImage width: {IMG_WIDTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y6cAOicJLgra",
   "metadata": {
    "id": "Y6cAOicJLgra"
   },
   "source": [
    "Lets plot some samples from `train_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WPTDLM3VK-wM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "WPTDLM3VK-wM",
    "outputId": "7778cb11-9d3d-459b-92f1-cc769f7a0a32"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure()\n",
    "n_samples = 4\n",
    "for i in range(1, n_samples + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[int(sample_idx)]\n",
    "    figure.add_subplot(1, n_samples, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BlhloP_MJLNw",
   "metadata": {
    "id": "BlhloP_MJLNw"
   },
   "source": [
    "## Parameters\n",
    "\n",
    "Here we list some of the parameters that will be combined inside of the training and testing stage for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vh7_q86dJN8G",
   "metadata": {
    "id": "Vh7_q86dJN8G"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "LOSSES = [\n",
    "    nn.CrossEntropyLoss(),\n",
    "    nn.NLLLoss(),\n",
    "]\n",
    "\n",
    "OPTIMIZERS = [\n",
    "    torch.optim.SGD,\n",
    "    torch.optim.Adam,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NKh8KbjzgRnZ",
   "metadata": {
    "id": "NKh8KbjzgRnZ"
   },
   "source": [
    "## Model testing\n",
    "\n",
    "The following function deals with the verification of a trained model against the `test_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fYrPkT_ck6gp",
   "metadata": {
    "id": "fYrPkT_ck6gp"
   },
   "outputs": [],
   "source": [
    "def test(model: nn.Module, loss_fn, loader: DataLoader=test_loader):\n",
    "    print(\"=> Running the test...\")\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss, n_correct = 0.0, 0\n",
    "    with torch.no_grad():  # The autograd should be disabled in testing\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            test_loss += loss_fn(pred, y_batch).item()\n",
    "            n_correct += (pred.argmax(1) == y_batch).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= len(loader)\n",
    "    n_correct /= len(loader.dataset)\n",
    "    print(f\"Accuracy: {100 * n_correct}\\nAvg. loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hTqml84WnXXm",
   "metadata": {
    "id": "hTqml84WnXXm"
   },
   "source": [
    "We now create a function to combine the above defined hyperparameters in order to test their performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fe598aew7DI9",
   "metadata": {
    "id": "Fe598aew7DI9"
   },
   "outputs": [],
   "source": [
    "def test_hyperparams(\n",
    "    model,\n",
    "    train_fn,\n",
    "    lr=[LEARNING_RATE],\n",
    "    losses=LOSSES,\n",
    "    optimizers=OPTIMIZERS,\n",
    "):\n",
    "    print(f\"{'Hyperparameter test':=^80}\")\n",
    "    print(f\"=> Model: {model}\")\n",
    "    params = itertools.product(lr, losses, optimizers)\n",
    "    for idx, (lr, loss_fn, op) in enumerate(params):\n",
    "        print(\n",
    "            \"\\n\\n=> Hyperparameters {}:\\n\"\n",
    "            f\"\\tlearning rate: {lr}\\n\"\n",
    "            f\"\\tloss function: {loss_fn}\\n\"\n",
    "            f\"\\toptimizer: {op}\\n\"\n",
    "        )\n",
    "        train_fn(model, train_loader, loss_fn, op)\n",
    "        print()\n",
    "        test(model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2FGEt2E-qN_i",
   "metadata": {
    "id": "2FGEt2E-qN_i"
   },
   "source": [
    "# Fully connected neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vm0GYCvt7jPP",
   "metadata": {
    "id": "vm0GYCvt7jPP"
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WoWprF36qQjG",
   "metadata": {
    "id": "WoWprF36qQjG"
   },
   "outputs": [],
   "source": [
    "class FullyConnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin_relu_seq = nn.Sequential(\n",
    "            nn.Linear(IMG_HEIGHT * IMG_WIDTH, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        X = self.lin_relu_seq(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "def fc_train(\n",
    "    fc_model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    lr=LEARNING_RATE,\n",
    "    n_epochs=5,\n",
    "    verbose=True\n",
    "):\n",
    "    print(\"=> Training the model...\")\n",
    "    optimizer = optimizer(fc_model.parameters(), lr=lr)\n",
    "    fc_model.train()  # Set the model to training mode\n",
    "    for epoch in range(n_epochs):\n",
    "        loss, n_correct = 0.0, 0\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "            pred = fc_model(X_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Total correct predictions\n",
    "            n_correct += (pred.argmax(1) == y_batch).type(torch.float).sum().item()\n",
    "\n",
    "        acc = 100.0 * (n_correct / len(loader.dataset))\n",
    "        if verbose:\n",
    "            print(f\"[Epoch {epoch}] Accuracy: {acc:0.3f}\\tLoss: {loss:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94Md0Rp17fc_",
   "metadata": {
    "id": "94Md0Rp17fc_"
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qp_ZBy_Y7l-c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qp_ZBy_Y7l-c",
    "outputId": "45792b4d-0c79-40e2-e20a-c919d5b706f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================Hyperparameter test===============================\n",
      "=> Model: FullyConnNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (lin_relu_seq): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: CrossEntropyLoss()\n",
      "\toptimizer: <class 'torch.optim.sgd.SGD'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 44.138\tLoss: 2.094\n",
      "[Epoch 1] Accuracy: 70.975\tLoss: 1.696\n",
      "[Epoch 2] Accuracy: 75.385\tLoss: 1.569\n",
      "[Epoch 3] Accuracy: 78.775\tLoss: 1.189\n",
      "[Epoch 4] Accuracy: 81.058\tLoss: 1.107\n",
      "=> Running the test...\n",
      "Accuracy: 83.21\n",
      "Avg. loss: 0.9451547599142525\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: CrossEntropyLoss()\n",
      "\toptimizer: <class 'torch.optim.adam.Adam'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 93.778\tLoss: 0.109\n",
      "[Epoch 1] Accuracy: 97.210\tLoss: 0.067\n",
      "[Epoch 2] Accuracy: 98.138\tLoss: 0.041\n",
      "[Epoch 3] Accuracy: 98.683\tLoss: 0.041\n",
      "[Epoch 4] Accuracy: 99.060\tLoss: 0.022\n",
      "=> Running the test...\n",
      "Accuracy: 97.74000000000001\n",
      "Avg. loss: 0.06958435685077244\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: NLLLoss()\n",
      "\toptimizer: <class 'torch.optim.sgd.SGD'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 99.427\tLoss: 0.021\n",
      "[Epoch 1] Accuracy: 99.548\tLoss: 0.005\n",
      "[Epoch 2] Accuracy: 99.602\tLoss: 0.004\n",
      "[Epoch 3] Accuracy: 99.630\tLoss: 0.015\n",
      "[Epoch 4] Accuracy: 99.648\tLoss: 0.008\n",
      "=> Running the test...\n",
      "Accuracy: 98.15\n",
      "Avg. loss: 0.05873461883028696\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: NLLLoss()\n",
      "\toptimizer: <class 'torch.optim.adam.Adam'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 99.168\tLoss: 0.018\n",
      "[Epoch 1] Accuracy: 99.470\tLoss: 0.001\n",
      "[Epoch 2] Accuracy: 99.573\tLoss: 0.000\n",
      "[Epoch 3] Accuracy: 99.655\tLoss: 0.021\n",
      "[Epoch 4] Accuracy: 99.680\tLoss: 0.011\n",
      "=> Running the test...\n",
      "Accuracy: 97.76\n",
      "Avg. loss: 0.08471411618531628\n"
     ]
    }
   ],
   "source": [
    "fc_model = FullyConnNet().to(DEVICE)\n",
    "test_hyperparams(fc_model, fc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yxgkIW7GFO5q",
   "metadata": {
    "id": "yxgkIW7GFO5q"
   },
   "source": [
    "# Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PFx19b7mQRzF",
   "metadata": {
    "id": "PFx19b7mQRzF"
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D3N7yNytFQBr",
   "metadata": {
    "id": "D3N7yNytFQBr"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel_size=5, mp_kernel_size=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_seq = nn.Sequential(\n",
    "            # Conv 1\n",
    "            nn.Conv2d(1, 32, kernel_size=kernel_size),\n",
    "            nn.ReLU(),\n",
    "            # Conv 2\n",
    "            nn.Conv2d(32, 32, kernel_size=kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(mp_kernel_size),\n",
    "            nn.Dropout(),\n",
    "            # Conv 3\n",
    "            nn.Conv2d(32, 64, kernel_size=kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(mp_kernel_size),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "        self.fully_conn_seq = nn.Sequential(\n",
    "            # Fully connected 1\n",
    "            nn.Linear(3 * 3 * 64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            # Fully connected 2\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv_seq(X)\n",
    "        X = X.view(-1, 3 * 3 * 64)\n",
    "        X = self.fully_conn_seq(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "def cnn_train(\n",
    "    cnn_model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    lr=LEARNING_RATE,\n",
    "    n_epochs=5,\n",
    "    verbose=True\n",
    "):\n",
    "    print(\"=> Training the model...\")\n",
    "    optimizer = optimizer(cnn_model.parameters(), lr=lr)\n",
    "    cnn_model.train()  # Set the model to training mode\n",
    "    for epoch in range(n_epochs):\n",
    "        loss, n_correct = 0.0, 0\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "            pred = cnn_model(X_batch)\n",
    "\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  # Reset optimizer gradients\n",
    "\n",
    "            # Total correct predictions\n",
    "            n_correct += (pred.argmax(1) == y_batch).type(torch.float).sum().item()\n",
    "\n",
    "        acc = 100.0 * (n_correct / len(loader.dataset))\n",
    "        if verbose:\n",
    "            print(f\"[Epoch {epoch}] Accuracy: {acc:0.3f}\\tLoss: {loss:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VWPfHTn_QXvH",
   "metadata": {
    "id": "VWPfHTn_QXvH"
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dujpyptG9UTc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dujpyptG9UTc",
    "outputId": "e69c0cae-3a35-479a-aead-611a3ab7e949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================Hyperparameter test===============================\n",
      "=> Model: CNN(\n",
      "  (conv_seq): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fully_conn_seq): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: CrossEntropyLoss()\n",
      "\toptimizer: <class 'torch.optim.sgd.SGD'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 10.112\tLoss: 2.305\n",
      "[Epoch 1] Accuracy: 11.742\tLoss: 2.293\n",
      "[Epoch 2] Accuracy: 14.135\tLoss: 2.273\n",
      "[Epoch 3] Accuracy: 18.553\tLoss: 2.241\n",
      "[Epoch 4] Accuracy: 27.195\tLoss: 2.091\n",
      "=> Running the test...\n",
      "Accuracy: 65.09\n",
      "Avg. loss: 1.9190677639785085\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: CrossEntropyLoss()\n",
      "\toptimizer: <class 'torch.optim.adam.Adam'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 91.705\tLoss: 0.091\n",
      "[Epoch 1] Accuracy: 96.905\tLoss: 0.148\n",
      "[Epoch 2] Accuracy: 97.530\tLoss: 0.015\n",
      "[Epoch 3] Accuracy: 97.878\tLoss: 0.051\n",
      "[Epoch 4] Accuracy: 98.177\tLoss: 0.028\n",
      "=> Running the test...\n",
      "Accuracy: 99.26\n",
      "Avg. loss: 0.024300770647230612\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: NLLLoss()\n",
      "\toptimizer: <class 'torch.optim.sgd.SGD'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 98.253\tLoss: 0.033\n",
      "[Epoch 1] Accuracy: 98.487\tLoss: 0.008\n",
      "[Epoch 2] Accuracy: 98.490\tLoss: 0.009\n",
      "[Epoch 3] Accuracy: 98.492\tLoss: 0.003\n",
      "[Epoch 4] Accuracy: 98.623\tLoss: 0.006\n",
      "=> Running the test...\n",
      "Accuracy: 99.41\n",
      "Avg. loss: 0.018974098387310744\n",
      "\n",
      "\n",
      "=> Hyperparameters:\n",
      "\tlearning rate: 0.001\n",
      "\tloss function: NLLLoss()\n",
      "\toptimizer: <class 'torch.optim.adam.Adam'>\n",
      "\n",
      "=> Training the model...\n",
      "[Epoch 0] Accuracy: 98.250\tLoss: 0.092\n",
      "[Epoch 1] Accuracy: 98.428\tLoss: 0.294\n",
      "[Epoch 2] Accuracy: 98.503\tLoss: 0.020\n",
      "[Epoch 3] Accuracy: 98.555\tLoss: 0.167\n",
      "[Epoch 4] Accuracy: 98.575\tLoss: 0.015\n",
      "=> Running the test...\n",
      "Accuracy: 99.38\n",
      "Avg. loss: 0.020565229724050102\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN().to(DEVICE)\n",
    "test_hyperparams(cnn_model, cnn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_3QXTguRH9Qs",
   "metadata": {
    "id": "_3QXTguRH9Qs"
   },
   "source": [
    "# Bibliography\n",
    "\n",
    "* [Pytorch quickstart tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html).\n",
    "* [Pytorch documentation](https://pytorch.org/docs/stable/index.html).\n",
    "* [Neuromatch Academy: Deep Learning](https://deeplearning.neuromatch.io/tutorials/intro.html).\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
